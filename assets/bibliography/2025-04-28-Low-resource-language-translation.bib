@article{team2022NoLL,
  title={No Language Left Behind: Scaling Human-Centered Machine Translation},
  author={Marta Ruiz Costa-juss{\`a} and James Cross and Onur cCelebi and Maha Elbayad and Kenneth Heafield and Kevin Heffernan and Elahe Kalbassi and Janice Lam and Daniel Licht and Jean Maillard and Anna Sun and Skyler Wang and Guillaume Wenzek and Alison Youngblood and Bapi Akula and Lo{\"i}c Barrault and Gabriel Mejia Gonzalez and Prangthip Hansanti and John Hoffman and Semarley Jarrett and Kaushik Ram Sadagopan and Dirk Rowe and Shannon L. Spruit and C. Tran and Pierre Yves Andrews and Necip Fazil Ayan and Shruti Bhosale and Sergey Edunov and Angela Fan and Cynthia Gao and Vedanuj Goswami and Francisco Guzm'an and Philipp Koehn and Alexandre Mourachko and Christophe Ropers and Safiyyah Saleem and Holger Schwenk and Jeff Wang},
  journal={ArXiv},
  year={2022},
  volume={abs/2207.04672},
  url={https://api.semanticscholar.org/CorpusID:250425961}
}

@book{Eberhard2024Ethnologue,
  title = {Ethnologue: Languages of the World},
  edition = {Twenty-seventh},
  publisher = {SIL International},
  year = {2024},
  editor = {Eberhard, David M. and Simons, Gary F. and Fennig, Charles D.},
  address = {Dallas, Texas},
  url = {http://www.ethnologue.com}
}

@article{Touvron2023Llama2O,
  title={Llama 2: Open Foundation and Fine-Tuned Chat Models},
  author={Hugo Touvron and Louis Martin and Kevin R. Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Daniel M. Bikel and Lukas Blecher and Cristian Cant{\'o}n Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony S. Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel M. Kloumann and A. V. Korenev and Punit Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and R. Subramanian and Xia Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zhengxu Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
  journal={ArXiv},
  year={2023},
  volume={abs/2307.09288},
  url={https://api.semanticscholar.org/CorpusID:259950998}
}

@article{Nguyen2023SeaLLMsL,
  title={SeaLLMs - Large Language Models for Southeast Asia},
  author={Xuan-Phi Nguyen and Wenxuan Zhang and Xin Li and Mahani Aljunied and Qingyu Tan and Liying Cheng and Guanzheng Chen and Yue Deng and Sen Yang and Chaoqun Liu and Hang Zhang and Li Bing},
  journal={ArXiv},
  year={2023},
  volume={abs/2312.00738},
  url={https://api.semanticscholar.org/CorpusID:265551745}
}

@misc{lowphansirikul2021wangchanberta,
    title={WangchanBERTa: Pretraining transformer-based Thai Language Models},
    author={Lalita Lowphansirikul and Charin Polpanumas and Nawat Jantrakulchai and Sarana Nutanong},
    year={2021},
    eprint={2101.09635},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{Brown2020LanguageMA,
  title={Language Models are Few-Shot Learners},
  author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeff Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
  journal={ArXiv},
  year={2020},
  volume={abs/2005.14165},
  url={https://api.semanticscholar.org/CorpusID:218971783}
}

@article{Jiang2023Mistral7,
  title={Mistral 7B},
  author={Albert Qiaochu Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and Devendra Singh Chaplot and Diego de Las Casas and Florian Bressand and Gianna Lengyel and Guillaume Lample and Lucile Saulnier and L'elio Renard Lavaud and Marie-Anne Lachaux and Pierre Stock and Teven Le Scao and Thibaut Lavril and Thomas Wang and Timoth{\'e}e Lacroix and William El Sayed},
  journal={ArXiv},
  year={2023},
  volume={abs/2310.06825},
  url={https://api.semanticscholar.org/CorpusID:263830494}
}


@article{nekoto2020participatory,
  title={Participatory research for low-resourced machine translation: A case study in african languages},
  author={Nekoto, Wilhelmina and Marivate, Vukosi and Matsila, Tshinondiwa and Fasubaa, Timi and Kolawole, Tajudeen and Fagbohungbe, Taiwo and Akinola, Solomon Oluwole and Muhammad, Shamsuddeen Hassan and Kabongo, Salomon and Osei, Salomey and others},
  journal={arXiv preprint arXiv:2010.02353},
  year={2020}
}

@inproceedings{leong-etal-2022-bloom,
    title = "Bloom Library: Multimodal Datasets in 300+ Languages for a Variety of Downstream Tasks",
    author = "Leong, Colin  and
      Nemecek, Joshua  and
      Mansdorfer, Jacob  and
      Filighera, Anna  and
      Owodunni, Abraham  and
      Whitenack, Daniel",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.590",
    doi = "10.18653/v1/2022.emnlp-main.590",
    pages = "8608--8621",
    abstract = "We present Bloom Library, a linguistically diverse set of multimodal and multilingual datasets for language modeling, image captioning, visual storytelling, and speech synthesis/recognition. These datasets represent either the most, or among the most, multilingual datasets for each of the included downstream tasks. In total, the initial release of the Bloom Library datasets covers 363 languages across 32 language families. We train downstream task models for various languages represented in the data, showing the viability of the data for future work in low-resource, multimodal NLP and establishing the first known baselines for these downstream tasks in certain languages (e.g., Bisu [bzi], with an estimated population of 700 users). Some of these first-of-their-kind baselines are comparable to state-of-the-art performance for higher-resourced languages. The Bloom Library datasets are released under Creative Commons licenses on the Hugging Face datasets hub to catalyze more linguistically diverse research in the included downstream tasks.",
}


@article{moslem2023adaptive,
  title={Adaptive machine translation with large language models},
  author={Moslem, Yasmin and Haque, Rejwanul and Kelleher, John D and Way, Andy},
  journal={arXiv preprint arXiv:2301.13294},
  year={2023}
}

@article{agrawal2022context,
  title={In-context examples selection for machine translation},
  author={Agrawal, Sweta and Zhou, Chunting and Lewis, Mike and Zettlemoyer, Luke and Ghazvininejad, Marjan},
  journal={arXiv preprint arXiv:2212.02437},
  year={2022}
}

@article{li2023eliciting,
  title={Eliciting the translation ability of large language models via multilingual finetuning with translation instructions},
  author={Li, Jiahuan and Zhou, Hao and Huang, Shujian and Chen, Shanbo and Chen, Jiajun},
  journal={arXiv preprint arXiv:2305.15083},
  year={2023}
}

@inproceedings{zhang-etal-2020-improving,
    title = "Improving Massively Multilingual Neural Machine Translation and Zero-Shot Translation",
    author = "Zhang, Biao  and
      Williams, Philip  and
      Titov, Ivan  and
      Sennrich, Rico",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.148",
    doi = "10.18653/v1/2020.acl-main.148",
    pages = "1628--1639",
    abstract = "Massively multilingual models for neural machine translation (NMT) are theoretically attractive, but often underperform bilingual models and deliver poor zero-shot translations. In this paper, we explore ways to improve them. We argue that multilingual NMT requires stronger modeling capacity to support language pairs with varying typological characteristics, and overcome this bottleneck via language-specific components and deepening NMT architectures. We identify the off-target translation issue (i.e. translating into a wrong target language) as the major source of the inferior zero-shot performance, and propose random online backtranslation to enforce the translation of unseen training language pairs. Experiments on OPUS-100 (a novel multilingual dataset with 100 languages) show that our approach substantially narrows the performance gap with bilingual models in both one-to-many and many-to-many settings, and improves zero-shot performance by {\textasciitilde}10 BLEU, approaching conventional pivot-based methods.",
}
@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}
@article{liu2022few,
  title={Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning},
  author={Liu, Haokun and Tam, Derek and Muqeeth, Mohammed and Mohta, Jay and Huang, Tenghao and Bansal, Mohit and Raffel, Colin A},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={1950--1965},
  year={2022}
}

@article{alves2024tower,
  title={Tower: An Open Multilingual Large Language Model for Translation-Related Tasks},
  author={Alves, Duarte M and Pombal, Jos{\'e} and Guerreiro, Nuno M and Martins, Pedro H and Alves, Jo{\~a}o and Farajian, Amin and Peters, Ben and Rei, Ricardo and Fernandes, Patrick and Agrawal, Sweta and others},
  journal={arXiv preprint arXiv:2402.17733},
  year={2024}
}
@article{xie2021explanation,
  title={An explanation of in-context learning as implicit bayesian inference},
  author={Xie, Sang Michael and Raghunathan, Aditi and Liang, Percy and Ma, Tengyu},
  journal={arXiv preprint arXiv:2111.02080},
  year={2021}
}
@article{gala2023indictrans2,
  title={Indictrans2: Towards high-quality and accessible machine translation models for all 22 scheduled indian languages},
  author={Gala, Jay and Chitale, Pranjal A and AK, Raghavan and Doddapaneni, Sumanth and Gumma, Varun and Kumar, Aswanth and Nawale, Janki and Sujatha, Anupama and Puduppully, Ratish and Raghavan, Vivek and others},
  journal={arXiv preprint arXiv:2305.16307},
  year={2023}
}
@inproceedings{bouamor2014multidialectal,
  title={A Multidialectal Parallel Corpus of Arabic.},
  author={Bouamor, Houda and Habash, Nizar and Oflazer, Kemal},
  booktitle={LREC},
  pages={1240--1245},
  year={2014}
}

@article{fatehkia2024t,
  title={T-RAG: Lessons from the LLM Trenches},
  author={Fatehkia, Masoomali and Lucas, Ji Kim and Chawla, Sanjay},
  journal={arXiv preprint arXiv:2402.07483},
  year={2024}
}
@inproceedings{reimers-2019-sentence-bert,
  title = "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
  author = "Reimers, Nils and Gurevych, Iryna",
  booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
  month = "11",
  year = "2019",
  publisher = "Association for Computational Linguistics",
  url = "https://arxiv.org/abs/1908.10084",
}
@inproceedings{paul-etal-2009-importance,
    title = "On the Importance of Pivot Language Selection for Statistical Machine Translation",
    author = "Paul, Michael  and
      Yamamoto, Hirofumi  and
      Sumita, Eiichiro  and
      Nakamura, Satoshi",
    editor = "Ostendorf, Mari  and
      Collins, Michael  and
      Narayanan, Shri  and
      Oard, Douglas W.  and
      Vanderwende, Lucy",
    booktitle = "Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers",
    month = jun,
    year = "2009",
    address = "Boulder, Colorado",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N09-2056",
    pages = "221--224",
}
@misc{Hermes-2-Pro-Llama-3-8B, 
      url={[https://huggingface.co/NousResearch/Hermes-2-Pro-Llama-3-8B]https://huggingface.co/NousResearch/Hermes-2-Pro-Llama-3-8B)}, 
      title={Hermes-2-Pro-Llama-3-8B}, 
      author={"Teknium", "interstellarninja", "theemozilla", "karan4d", "huemin_art"}
}
@misc{llama3modelcard,
title={Llama 3 Model Card},
author={AI@Meta},
year={2024},
url = {https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md}
}
@inproceedings{papineni-etal-2002-bleu,
    title = "{B}leu: a Method for Automatic Evaluation of Machine Translation",
    author = "Papineni, Kishore  and
      Roukos, Salim  and
      Ward, Todd  and
      Zhu, Wei-Jing",
    editor = "Isabelle, Pierre  and
      Charniak, Eugene  and
      Lin, Dekang",
    booktitle = "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2002",
    address = "Philadelphia, Pennsylvania, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P02-1040",
    doi = "10.3115/1073083.1073135",
    pages = "311--318",
}

@manual{Majumdar2022ta,
  author = {Majumdar, Dattatreya},
  title = {Text Analysis and Distant Reading using R},
  note = {https://slcladal.github.io/lexsim.html},
  year = {2022},
  organization = "The University of Queensland, Australia. School of Languages and Cultures},
  address = {Brisbane},
  edition = {2022.09.13}
}
@book{ethnologue2024,
  editor    = {David M. Eberhard and Gary F. Simons and Charles D. Fennig},
  title     = {Ethnologue: Languages of the World},
  edition   = {27},
  year      = {2024},
  address   = {Dallas, Texas},
  publisher = {SIL International},
  url       = {https://www.ethnologue.com/},
  note      = {Online version}
}
@article{zhang2024scaling,
  title={When scaling meets llm finetuning: The effect of data, model and finetuning method},
  author={Zhang, Biao and Liu, Zhongtao and Cherry, Colin and Firat, Orhan},
  journal={arXiv preprint arXiv:2402.17193},
  year={2024}
}
@article{remy2024trans,
  title={Trans-tokenization and cross-lingual vocabulary transfers: Language adaptation of LLMs for low-resource NLP},
  author={Remy, Fran{\c{c}}ois and Delobelle, Pieter and Avetisyan, Hayastan and Khabibullina, Alfiya and de Lhoneux, Miryam and Demeester, Thomas},
  journal={arXiv preprint arXiv:2408.04303},
  year={2024}
}
@article{vieira2024much,
  title={How Much Data is Enough Data? Fine-Tuning Large Language Models for In-House Translation: Performance Evaluation Across Multiple Dataset Sizes},
  author={Vieira, Inacio and Allred, Will and Lankford, Seamus and De Sousa, Sheila Castilho Monteiro and Way, Andy},
  journal={arXiv preprint arXiv:2409.03454},
  year={2024}
}
@article{lester2021power,
  title={The power of scale for parameter-efficient prompt tuning},
  author={Lester, Brian and Al-Rfou, Rami and Constant, Noah},
  journal={arXiv preprint arXiv:2104.08691},
  year={2021}
}